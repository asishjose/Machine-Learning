{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b46e81-7393-444c-886d-b36053f5bb35",
   "metadata": {},
   "source": [
    "## Tuning Logistic Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e3f4a3-c75f-4a75-a1bd-0c7c437a84a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34963422-5852-4b9c-aa31-6917d66e46cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters:  {'C': np.float64(0.006105402296585327)}\n",
      "Best score is:  0.853\n",
      "Accuracy:  85.3\n"
     ]
    }
   ],
   "source": [
    "X,y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "c_space = np.logspace(-5,8,15)\n",
    "param_grid = {'C':c_space}\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR_cv = GridSearchCV(LR, param_grid, cv=5)\n",
    "LR_cv.fit(X,y)\n",
    "\n",
    "print('Tuned Logistic Regression Parameters: ',LR_cv.best_params_)\n",
    "print('Best score is: ',LR_cv.best_score_)\n",
    "print('Accuracy: ',LR_cv.best_score_*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb5b14-783d-49af-b0f3-5a8cc7ae5c88",
   "metadata": {},
   "source": [
    "This represents the highest accuracy achieved by the model using the hyperparameter combination,   ...C = 0.0061. The best score of 0.853 means the model achieved 85.3% accuracy on the validation data during the grid search process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76350d7-d1af-4de0-bdcb-75e960452e41",
   "metadata": {},
   "source": [
    "## 2. RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75656c32-2c90-4851-8c09-237626409178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(\n",
    "    n_samples = 1000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "379b86e3-9364-4a4d-b799-173eba0c128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': None, 'max_features': 7, 'min_samples_leaf': 1}\n",
      "Best score is: 0.8320000000000001\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"max_depth\":[3,None],\n",
    "    \"max_features\": randint(1,9),\n",
    "    \"min_samples_leaf\": randint(1,9),\n",
    "    \"criterion\": ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "tree_cv.fit(X,y)\n",
    "\n",
    "print(\"Tuned Decision Tree Parameters:\", tree_cv.best_params_)\n",
    "print('Best score is:', tree_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47280f-76d6-4a9f-a5c9-af1baa480af8",
   "metadata": {},
   "source": [
    "A score of 0.842 means the model performed with an accuracy of 84.2% on the validation set with following hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f760a83-9182-44f1-a3d9-c6ec7669d09b",
   "metadata": {},
   "source": [
    "## 3. Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77763a6f-0d1a-4b67-9ea8-0f13eb186e80",
   "metadata": {},
   "source": [
    "P(score(y)âˆ£hyperparameters(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9f94b-0949-4bde-bde9-6a0ce11264ee",
   "metadata": {},
   "source": [
    "It treats hyperparameter tuning like a mathematical optimization problem and learns from past results to decide what to try next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf933b2-ab68-42a9-8a33-b921d42c31fb",
   "metadata": {},
   "source": [
    "- Build a probabilistic model (surrogate function) that predicts performance based on hyperparameters.\n",
    "- Update this model after each evaluation.\n",
    "- Use the model to choose the next best set to try.\n",
    "- Repeat until the optimal combination is found. The surrogate function models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f6da5-5411-43d7-bdd0-017620342dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
